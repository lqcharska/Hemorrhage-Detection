{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import operator\n",
    "from enum import Enum\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "TEST_SET_SIZE = 0.3 # 1 - TEST_SET_SIZE (70%) - training set, TEST_SET_SIZE (30%) testing set\n",
    "VAL_SET_SIZE = 0.5  # 50% of testing set, it means\n",
    "                    # TEST_SET_SIZE / 2 (15%) - testing set, TEST_SET_SIZE / 2 (15%) validation set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def swap_target(x):\n",
    "    if x == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "class DatasetSplittingType(Enum):\n",
    "    kFOLD= 0\n",
    "    TRAIN_TEST = 1\n",
    "    TRAIN_VAL_TEST = 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "class HemorrageDataset:\n",
    "    def __init__(self, diagnoseCsvPath, folderPath):\n",
    "        self.__diagnoseCSV = pd.read_csv(diagnoseCsvPath)\n",
    "        self.__pathToWholeFolder = folderPath\n",
    "        self.__trainDataForLoading = []\n",
    "        self.__trainLabelsForLoading = []\n",
    "        self.__testDataForLoading = []\n",
    "        self.__testLabelsForLoading = []\n",
    "        self.__valDataForLoading = []\n",
    "        self.__valLabelsForLoading = []\n",
    "        self.__kFoldDataForLoading = []\n",
    "        self.__kFoldLabelsForLoading = []\n",
    "\n",
    "    def __kFoldSplitting(self, k, sickCases, healthyCases):\n",
    "        healthyLabels = [1 for i in range(len(healthyCases))]\n",
    "        sickLabels = [0 for i in range(len(sickCases))]\n",
    "        allCases = healthyCases + sickCases\n",
    "        allLabels = healthyLabels + sickLabels\n",
    "        allCases, allLabels = shuffle(allCases, allLabels)\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=1)\n",
    "        for train_index, test_index in skf.split(allCases, allLabels):\n",
    "            trainNumbersFold, testNumbersFold = operator.itemgetter(*train_index)(allCases), operator.itemgetter(*test_index)(allCases)\n",
    "            trainData, trainLabels = self.__prepareDataSavingPatienNumberAndSlice(trainNumbersFold)\n",
    "            testData, testLabels = self.__prepareDataSavingPatienNumberAndSlice(testNumbersFold)\n",
    "            self.__kFoldDataForLoading.append([trainData, testData])\n",
    "            self.__kFoldLabelsForLoading.append([trainLabels, testLabels])\n",
    "\n",
    "\n",
    "    def __subsetSplitting(self, sickCases, healthyCases):\n",
    "        trainHealthyPatientsNumbers, testHealthyPatientsNumbers = train_test_split(healthyCases, test_size=TEST_SET_SIZE,random_state=25, shuffle=True)\n",
    "        testHealthyPatientsNumbers, valHealthyPatientsNumbers = train_test_split(testHealthyPatientsNumbers, test_size=VAL_SET_SIZE,random_state=25, shuffle=True)\n",
    "        trainSickPatientsNumbers, testSickPatientsNumbers = train_test_split(sickCases, test_size=TEST_SET_SIZE,random_state=25, shuffle=True)\n",
    "        testSickPatientsNumbers, valSickPatientsNumbers = train_test_split(testSickPatientsNumbers, test_size=VAL_SET_SIZE,random_state=25, shuffle=True)\n",
    "\n",
    "        trainCases = trainHealthyPatientsNumbers + trainSickPatientsNumbers\n",
    "        trainCases = random.sample(trainCases, len(trainCases))\n",
    "        testCases = testHealthyPatientsNumbers + testSickPatientsNumbers\n",
    "        testCases = random.sample(testCases, len(testCases))\n",
    "        valCases = valHealthyPatientsNumbers + valSickPatientsNumbers\n",
    "        valCases = random.sample(valCases, len(valCases))\n",
    "        return trainCases, testCases, valCases\n",
    "\n",
    "    def __distinquishHealthyAndSickCases(self):\n",
    "        sickCases = []\n",
    "        healthyCases = []\n",
    "        for patientNum in np.unique(self.__diagnoseCSV['PatientNumber']):\n",
    "            isSick = self.__diagnoseCSV[(self.__diagnoseCSV['PatientNumber'] == patientNum)].Has_Hemorrhage.sum()\n",
    "            if isSick > 0:\n",
    "                sickCases.append(patientNum)\n",
    "            else:\n",
    "                healthyCases.append(patientNum)\n",
    "\n",
    "        return healthyCases, sickCases\n",
    "\n",
    "    def __prepareDataSavingPatienNumberAndSlice(self, chosenSet):\n",
    "        data = []\n",
    "        labels = []\n",
    "        for patientNum in chosenSet:\n",
    "            for sliceNum in np.unique(self.__diagnoseCSV.loc[(self.__diagnoseCSV['PatientNumber'] == patientNum)]['SliceNumber']):\n",
    "                diagnose = self.__diagnoseCSV.loc[(self.__diagnoseCSV['PatientNumber'] == patientNum)\n",
    "                                        & (self.__diagnoseCSV['SliceNumber'] == sliceNum)]['Has_Hemorrhage'].values[0]\n",
    "                data.append((patientNum, sliceNum))\n",
    "                labels.append(diagnose)\n",
    "\n",
    "        return data, labels\n",
    "\n",
    "    def splitDatasetBasedOnPatientsCases(self, splittingType, kFold = 0):\n",
    "         healthyPatientsNumbers, sickPatientsNumbers = self.__distinquishHealthyAndSickCases()\n",
    "\n",
    "         if(splittingType == DatasetSplittingType.kFOLD):\n",
    "             self.__kFoldSplitting(kFold, sickPatientsNumbers, healthyPatientsNumbers)\n",
    "         elif ((splittingType == DatasetSplittingType.TRAIN_VAL_TEST) or (splittingType == DatasetSplittingType.TRAIN_TEST)):\n",
    "             trainSubset, testSubset, valSubset = self.__subsetSplitting(sickPatientsNumbers, healthyPatientsNumbers)\n",
    "             self.__trainDataForLoading, self.__trainLabelsForLoading = self.__prepareDataSavingPatienNumberAndSlice(trainSubset)\n",
    "             self.__testDataForLoading, self.__testLabelsForLoading = self.__prepareDataSavingPatienNumberAndSlice(testSubset)\n",
    "             self.__valDataForLoading, self.__valLabelsForLoading = self.__prepareDataSavingPatienNumberAndSlice(valSubset)\n",
    "\n",
    "             if(splittingType == DatasetSplittingType.TRAIN_TEST):\n",
    "                 self.__testDataForLoading += self.__valDataForLoading\n",
    "                 self.__testLabelsForLoading += self.__valLabelsForLoading\n",
    "                 self.__valDataForLoading = []\n",
    "                 self.__valLabelsForLoading= []\n",
    "\n",
    "    def removeRecordFromDataset(self, patientNum, sliceNumber):\n",
    "        # Remove corrupted images or with missing brain/bone windowed images\n",
    "        index_to_drop = self.__diagnoseCSV[(self.__diagnoseCSV['PatientNumber'] == patientNum) & (self.__diagnoseCSV['SliceNumber'] == sliceNumber)].index\n",
    "        index_to_drop = index_to_drop[0]\n",
    "        self.__diagnoseCSV = self.__diagnoseCSV.drop(index_to_drop, axis=0)\n",
    "\n",
    "\n",
    "    def invertBinaryValues(self, colToChangeAndRemove, newCol):\n",
    "        self.__diagnoseCSV[newCol] = self.__diagnoseCSV[colToChangeAndRemove].apply(swap_target)\n",
    "        self.__diagnoseCSV = self.__diagnoseCSV.drop(colToChangeAndRemove, axis=1)\n",
    "\n",
    "    def get_trainDataWithLabels(self):\n",
    "        return self.__trainDataForLoading, self.__trainLabelsForLoading\n",
    "\n",
    "    def get_testDataWithLabels(self):\n",
    "        return self.__testDataForLoading, self.__testLabelsForLoading\n",
    "\n",
    "    def get_valDataWithLabels(self):\n",
    "        return self.__valDataForLoading, self.__valLabelsForLoading\n",
    "\n",
    "    def get_kFoldDataWithLabels(self):\n",
    "        return self.__kFoldDataForLoading, self.__kFoldLabelsForLoading"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# Create class for ml method - load images, preprocess, choose method and fit model\n",
    "# another class for statistic and visualization -> acces private property: self._Parent__private(), self.__demographyCSV = pd.read_csv(demographyCsvPath)\n",
    "# generator for all\n",
    "# for imbalanced dataset: https://machinelearningmastery.com/cost-sensitive-svm-for-imbalanced-classification/"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "basePath  = os.path.join(os.getcwd(), \"data\")\n",
    "csvPath = os.path.join(basePath, \"hemorrhage_diagnosis_raw_ct.csv\")\n",
    "dataset = HemorrageDataset(csvPath, basePath)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# Prepare csv file\n",
    "dataset.removeRecordFromDataset(84, 36)\n",
    "dataset.invertBinaryValues('No_Hemorrhage', 'Has_Hemorrhage')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# Split dataset using chosen method\n",
    "dataset.splitDatasetBasedOnPatientsCases(DatasetSplittingType.TRAIN_VAL_TEST)\n",
    "trainData, trainLabels = dataset.get_trainDataWithLabels()\n",
    "testData, testLabels = dataset.get_testDataWithLabels()\n",
    "valData, valLabels = dataset.get_valDataWithLabels()\n",
    "dataset.splitDatasetBasedOnPatientsCases(DatasetSplittingType.kFOLD, 10)\n",
    "kfoldData, kfoldLabel = dataset.get_kFoldDataWithLabels()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}